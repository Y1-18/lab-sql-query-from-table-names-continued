{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d930c89-4954-4e39-be5a-601c1dd89512",
   "metadata": {
    "id": "7d930c89-4954-4e39-be5a-601c1dd89512"
   },
   "source": [
    "# SQL query from table names - Continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a03f026a",
   "metadata": {
    "id": "a03f026a"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a05b80-88fd-42b2-ba89-763074ae74e9",
   "metadata": {
    "id": "53a05b80-88fd-42b2-ba89-763074ae74e9"
   },
   "source": [
    "## The old Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922f8d24",
   "metadata": {
    "id": "922f8d24"
   },
   "outputs": [],
   "source": [
    "#The old prompt\n",
    "\n",
    "\n",
    "old_context = [ {'role':'system', 'content':\"\"\"\n",
    "you are a bot to assist in create SQL commands, all your answers should start with \\\n",
    "this is your SQL, and after that an SQL that can do what the user request. \\\n",
    "Your Database is composed by a SQL database with some tables. \\\n",
    "Try to maintain the SQL order simple.\n",
    "Put the SQL command in white letters with a black background, and just after \\\n",
    "a simple and concise text explaining how it works.\n",
    "If the user ask for something that can not be solved with an SQL Order \\\n",
    "just answer something nice and simple, maximum 10 words, asking him for something that \\\n",
    "can be solved with SQL.\n",
    "\"\"\"} ]\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "first table:\n",
    "{\n",
    "  \"tableName\": \"employees\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"nombre\": \"ID_usr\",\n",
    "      \"tipo\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"nombre\": \"name\",\n",
    "      \"tipo\": \"varchar\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "second table:\n",
    "{\n",
    "  \"tableName\": \"salary\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"nombre\": \"ID_usr\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"year\",\n",
    "      \"type\": \"date\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"salary\",\n",
    "      \"type\": \"float\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "third table:\n",
    "{\n",
    "  \"tablename\": \"studies\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"name\": \"ID\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"ID_usr\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"educational_level\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Institution\",\n",
    "      \"type\": \"varchar\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Years\",\n",
    "      \"type\": \"date\"\n",
    "    }\n",
    "    {\n",
    "      \"name\": \"Speciality\",\n",
    "      \"type\": \"varchar\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377acaae-7dd0-4d13-bc68-9e33741c231c",
   "metadata": {
    "id": "377acaae-7dd0-4d13-bc68-9e33741c231c"
   },
   "source": [
    "## New Prompt.\n",
    "We are going to improve it following the instructions of a Paper from the Ohaio University: [How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings](https://arxiv.org/abs/2305.11853). I recommend you read that paper.\n",
    "\n",
    "For each table, we will define the structure using the same syntax as in a SQL create table command, and add the sample rows of the content.\n",
    "\n",
    "Finally, at the end of the prompt, we'll include some example queries with the SQL that the model should generate. This technique is called Few-Shot Samples, in which we provide the prompt with some examples to assist it in generating the correct SQL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5334f942",
   "metadata": {
    "id": "5334f942"
   },
   "outputs": [],
   "source": [
    "context = [ {'role':'system', 'content':\"\"\"\n",
    " CREATE SEVERAL (3+) TABLES HERE\n",
    "\"\"\"} ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330e69b0-3f5f-4bb2-8185-aedded2bb993",
   "metadata": {
    "id": "330e69b0-3f5f-4bb2-8185-aedded2bb993"
   },
   "outputs": [],
   "source": [
    "#FEW SHOT SAMPLES\n",
    "context.append( {'role':'system', 'content':\"\"\"\n",
    " -- Maintain the SQL order simple and efficient as you can, using valid SQL Lite, answer the following questions for the table provided above.\n",
    "WRITE IN YOUR CONTEXT QUERIES HERE      \n",
    "create table employees(\n",
    "    ID_Usr INT primary key,\n",
    "    name VARCHAR);\n",
    "             \n",
    "    /*3 example rows\n",
    "    select * from employees limit 3;\n",
    "    ID_Usr    name\n",
    "    1456      Amanda Nunes\n",
    "    2345      Khabib Nurmagomedov\n",
    "    1678      Israel Adesanya\n",
    "    */\n",
    "\n",
    "create table salary(\n",
    "    ID_Usr INT,\n",
    "    year DATE,\n",
    "    salary FLOAT,\n",
    "    foreign key (ID_Usr) references employees(ID_Usr));\n",
    "             \n",
    "    /*3 example rows\n",
    "    select * from salary limit 3;\n",
    "    ID_Usr    year          salary\n",
    "    1456      01/01/2022    72000\n",
    "    2345      01/01/2023    85000\n",
    "    1678      01/01/2023    65000\n",
    "    */\n",
    "\n",
    "create table studies(\n",
    "    ID_study INT,\n",
    "    ID_Usr INT,\n",
    "    educational_level INT,  /* 5=phd, 4=Master, 3=Bachelor */\n",
    "    Institution VARCHAR,\n",
    "    Years DATE,\n",
    "    Speciality VARCHAR,\n",
    "    primary key (ID_study, ID_Usr),\n",
    "    foreign key(ID_Usr) references employees (ID_Usr));\n",
    "             \n",
    "    /*3 example rows\n",
    "    select * from studies limit 3\n",
    "    ID_Study ID_Usr educational_level Institution         Years       Speciality\n",
    "    3451     1456   3                 University of Miami 01/01/2011  Bachelor of Mathmatics \n",
    "    4567     2345   5                 Stanford University 01/01/2019  PhD in Computer Science\n",
    "    5678     1678   4                 Oxford University   01/01/2021  Master of Business Administration\n",
    "    */\n",
    "\"\"\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90f417a",
   "metadata": {
    "id": "b90f417a"
   },
   "outputs": [],
   "source": [
    "#Functio to call the model.\n",
    "def return_CCRMSQL(user_message, context):\n",
    "    client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "    newcontext = context.copy()\n",
    "    newcontext.append({'role':'user', 'content':\"question: \" + user_message})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=newcontext,\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "    return (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0a4c11-dfe1-46fe-ac2b-3ff825f9749c",
   "metadata": {
    "id": "9e0a4c11-dfe1-46fe-ac2b-3ff825f9749c"
   },
   "source": [
    "## NL2SQL Samples\n",
    "We're going to review some examples generated with the old prompt and others with the new prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e8202c-ce34-487e-9037-c65a263423ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59e8202c-ce34-487e-9037-c65a263423ed",
    "outputId": "f7a97b9f-45d7-4f78-8979-a796c5bc42fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT COUNT(*) AS num_students\n",
      "FROM studies\n",
      "WHERE Speciality LIKE '%Mathematics%';\n",
      "```\n",
      "This query will count the number of students whose specialty includes the word \"Mathematics\" in the `studies` table.\n"
     ]
    }
   ],
   "source": [
    "#new\n",
    "context_user = context.copy()\n",
    "print(return_CCRMSQL(\"\"\"Find number of student in Mathmatics\"\"\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c4766b1-48a9-456e-bc6c-4b6f41909aa4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c4766b1-48a9-456e-bc6c-4b6f41909aa4",
    "outputId": "029844da-5f1f-4f65-9adb-4d9c1cafacea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your SQL:\n",
      "```sql\n",
      "SELECT COUNT(*) \n",
      "FROM studies \n",
      "WHERE Institution = 'Stanford University';\n",
      "```\n",
      "\n",
      "This SQL query counts the number of students in the \"studies\" table who attended Stanford University by filtering the rows where the \"Institution\" column has the value 'Stanford University'.\n"
     ]
    }
   ],
   "source": [
    "#old\n",
    "old_context_user = old_context.copy()\n",
    "print(return_CCRMSQL(\"How many student in Stanford University\", old_context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38d8d370-0524-4a28-bd54-5e5cddb08e2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38d8d370-0524-4a28-bd54-5e5cddb08e2c",
    "outputId": "2934cdec-bea0-44db-b047-33e70dcf8ae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT e.name\n",
      "FROM employees e\n",
      "JOIN studies s ON e.ID_Usr = s.ID_Usr\n",
      "WHERE s.Institution = 'Harvard University';\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "#new\n",
    "print(return_CCRMSQL(\"Find employees who studied at Harvard\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5aa318d4-dd9f-41db-8ff4-c1d87220f766",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5aa318d4-dd9f-41db-8ff4-c1d87220f766",
    "outputId": "605724a1-0d89-4ed9-d8ec-1aeeae6dc287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your SQL:\n",
      "```sql\n",
      "SELECT s.educational_level, AVG(s.salary) AS average_salary\n",
      "FROM salary s\n",
      "JOIN studies st ON s.ID_usr = st.ID_usr\n",
      "GROUP BY s.educational_level;\n",
      "```\n",
      "This SQL query retrieves the average salary for each educational level by joining the \"salary\" table with the \"studies\" table on the user ID. It then calculates the average salary for each educational level group using the AVG function and groups the results by educational level.\n"
     ]
    }
   ],
   "source": [
    "#old\n",
    "print(return_CCRMSQL(\"Get the average salary for each educational level. \", old_context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f31968e-74ad-4ae2-9537-b3d550b1be47",
   "metadata": {
    "id": "0f31968e-74ad-4ae2-9537-b3d550b1be47"
   },
   "source": [
    "# Exercise\n",
    " - Complete the prompts similar to what we did in class. \n",
    "     - Try at least 3 versions\n",
    "     - Be creative\n",
    " - Write a one page report summarizing your findings.\n",
    "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong.\n",
    "     - What did you learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dc7120a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT MAX(salary) AS highest_salary\n",
      "FROM salary;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(return_CCRMSQL(\"find the highest salary among all employees\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "078d6107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your SQL:\n",
      "```sql\n",
      "SELECT MAX(salary) AS highest_salary\n",
      "FROM salary;\n",
      "```\n",
      "\n",
      "This SQL query selects the maximum salary value from the \"salary\" table, giving you the highest salary among all employees.\n"
     ]
    }
   ],
   "source": [
    "print(return_CCRMSQL(\"find the highest salary among all employees\", old_context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3918f90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT s.Institution, AVG(sa.salary) AS avg_salary\n",
      "FROM employees e\n",
      "JOIN studies st ON e.ID_Usr = st.ID_Usr\n",
      "JOIN salary sa ON e.ID_Usr = sa.ID_Usr\n",
      "GROUP BY st.Institution;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(return_CCRMSQL(\"find the average salary of employees who studied grouped by universoty\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d2988b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your SQL:\n",
      "```sql\n",
      "SELECT s.Institution, AVG(sa.salary) AS average_salary\n",
      "FROM employees e\n",
      "JOIN studies st ON e.ID_usr = st.ID_usr\n",
      "JOIN salary sa ON e.ID_usr = sa.ID_usr\n",
      "GROUP BY s.Institution;\n",
      "```\n",
      "\n",
      "This SQL query joins the three tables (employees, studies, and salary) based on the employee ID. It then calculates the average salary of employees who studied at each university by grouping the results by the university.\n"
     ]
    }
   ],
   "source": [
    "print(return_CCRMSQL(\"find the average salary of employees who studied grouped by universoty\", old_context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1557d914",
   "metadata": {},
   "source": [
    "Introduction\n",
    "\n",
    "The Jupyter Notebook analyzed focuses on leveraging OpenAI’s GPT API to generate SQL queries dynamically based on structured table definitions. The approach includes prompt engineering, defining table structures in JSON format, and requesting SQL query generation through OpenAI’s API. The goal is to assist users in forming SQL commands efficiently.\n",
    "\n",
    "Findings and Observations\n",
    "\n",
    "The methodology used in the notebook was structured well, incorporating predefined context for three tables: employees, salary, and studies. The system prompt ensured GPT had a solid understanding of the table schemas, and subsequent user prompts requested SQL queries.\n",
    "\n",
    "However, there were instances where GPT exhibited issues, such as:\n",
    "\n",
    "Hallucinations in SQL Queries: At times, GPT introduced fields or table names that did not exist in the predefined schema. This resulted in SQL queries that referenced non-existent columns.\n",
    "\n",
    "Inconsistent SQL Syntax: Although most queries followed SQL conventions correctly, there were cases where GPT produced incorrect syntax, particularly when handling JOIN operations or aggregations.\n",
    "\n",
    "Ambiguity in Responses: Some SQL outputs were not concise or included unnecessary complexity, making them difficult to interpret or optimize.\n",
    "\n",
    "Lessons Learned\n",
    "\n",
    "Prompt Engineering is Crucial – The quality of the prompt significantly affects the SQL output. Providing detailed and structured context improves accuracy.\n",
    "\n",
    "Verification is Necessary – GPT-generated SQL should always be reviewed before execution to ensure correctness and efficiency.\n",
    "\n",
    "Predefining Constraints Helps – By explicitly defining column data types and table relationships, hallucinations and incorrect joins can be minimized.\n",
    "\n",
    "Conclusion\n",
    "\n",
    "While GPT is a powerful tool for SQL generation, its reliability depends on structured prompts and human oversight. Further refinements, such as enforcing stricter validation mechanisms or fine-tuning the prompt structure, could improve its accuracy and usefulness in real-world applications.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5436b8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "AI_Enginnring",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
